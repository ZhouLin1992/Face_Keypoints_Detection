{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import csv\n",
    "import shelve\n",
    "import pickle\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "from pandas.io.parsers import read_csv\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import cm\n",
    "\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from datetime import datetime\n",
    "from matplotlib import cm\n",
    "from sklearn import metrics\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.mixture import GMM\n",
    "from matplotlib.colors import LogNorm\n",
    "\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from lasagne import layers\n",
    "from lasagne.updates import nesterov_momentum\n",
    "from nolearn.lasagne import NeuralNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "import theano\n",
    "from theano import tensor as T\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams\n",
    "from theano.tensor.nnet.conv import conv2d\n",
    "from theano.tensor.signal.downsample import max_pool_2d\n",
    "print (theano.config.device) # We're using CPUs (for now)\n",
    "print (theano.config.floatX) # Should be 64 bit for CPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test data: (1783, 9216), test id : (1783, 1)\n",
      "train data: (5991, 9216), train coordinates: (5991, 30)\n",
      "dev data: (1057, 9216), dev coordinates: (1057, 30)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:33: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n",
      "/home/linux/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:34: VisibleDeprecationWarning: using a non-integer number instead of an integer will result in an error in the future\n"
     ]
    }
   ],
   "source": [
    "# function to load a file\n",
    "def LoadFile(path):\n",
    "    coordinates, faces = [], []\n",
    "    with open(path) as csvfile:\n",
    "        # read the file and separate image and keypoint coordinates\n",
    "        facereader = csv.reader(csvfile, delimiter=',')\n",
    "        for row in facereader:\n",
    "            coordinates.append(row[0:-1])\n",
    "            faces.append(row[-1])\n",
    "        \n",
    "    # first line is header, pop it out    \n",
    "    coor_names, trash = coordinates.pop(0), faces.pop(0)\n",
    "    # covert everything to number   \n",
    "    for i in range(len(faces)):    \n",
    "        faces[i] = [int(x) for x in faces[i].split(' ')]\n",
    "        coordinates[i] = [float(x) if x else 0 for x in coordinates[i]]\n",
    "       \n",
    "    # convert to numpy array and return    \n",
    "    return np.array(faces), np.array(coordinates), np.array(coor_names)\n",
    "\n",
    "# load test data file\n",
    "test_faces, test_id, trash = LoadFile('./Data/FKD_Test.csv')\n",
    "print ('test data: %s, test id : %s' %(str(test_faces.shape), str(test_id.shape)))\n",
    "\n",
    "# load training data file, and separate it into training and dev data\n",
    "train_faces, train_coordinates, feature_name = LoadFile('./Data/FKD_Train.csv')\n",
    "nTotal = train_faces.shape[0]\n",
    "shuffle = np.random.permutation(np.arange(nTotal))\n",
    "train_faces, train_coordinates = train_faces[shuffle], train_coordinates[shuffle]\n",
    "\n",
    "# take 85% as training, 15% as dev \n",
    "nTrain = np.round(nTotal*.85)\n",
    "dev_faces, dev_coordinates = train_faces[nTrain:], train_coordinates[nTrain:]\n",
    "train_faces, train_coordinates = train_faces[1:nTrain], train_coordinates[1:nTrain]\n",
    "\n",
    "print ('train data: %s, train coordinates: %s' %(str(train_faces.shape), str(train_coordinates.shape)))\n",
    "print ('dev data: %s, dev coordinates: %s' %(str(dev_faces.shape), str(dev_coordinates.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training faces: 150\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/linux/anaconda3/lib/python3.5/site-packages/ipykernel/__main__.py:133: VisibleDeprecationWarning: non integer (and non boolean) array-likes will not be accepted as indices in the future\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training patches shape: (15, 361)\n",
      "training time: 0.0 minutes\n",
      "number of predicting faces: 1783\n",
      "Done! - Predict time: 52.1 minutes\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'_csv.reader' object has no attribute 'next'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-7878836b336c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    167\u001b[0m \u001b[0;31m# predicting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_faces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 169\u001b[0;31m \u001b[0mmps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetSubmission\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'./Data/FKD_IdLookupTable.csv'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeature_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-35-7878836b336c>\u001b[0m in \u001b[0;36mgetSubmission\u001b[0;34m(self, LookupTable, feature_name)\u001b[0m\n\u001b[1;32m     84\u001b[0m             \u001b[0;31m# read the lookup file\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0mlookupReader\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcsvfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdelimiter\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m','\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             \u001b[0mlookupRow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlookupReader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mrow\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mlookupReader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;31m# get the prediction based on image ID and feature name, and attach to the row\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: '_csv.reader' object has no attribute 'next'"
     ]
    }
   ],
   "source": [
    "class MeanPatchSearching:\n",
    "    # Initialize an instance of the class.\n",
    "    def __init__(self, patch_size=10, search_size=10, stretch=True):\n",
    "        self.patch_size = patch_size\n",
    "        self.search_size = search_size\n",
    "        self.isStretch = stretch\n",
    "        self.patch_index = np.array([[i,j] for i in range(-patch_size, patch_size+1) \n",
    "                                           for j in range(-patch_size, patch_size+1)])\n",
    "        self.search_index = np.array([[i,j] for i in range(-search_size, search_size+1) \n",
    "                                            for j in range(-search_size, search_size+1)])\n",
    "    \n",
    "    # train the model\n",
    "    def fit(self, train_faces, train_coordinates):\n",
    "        start = datetime.now()\n",
    "        # stretch input if needed\n",
    "        if False: #self.isStretch:\n",
    "            train_faces = np.array([self._histogramStretching(x) for x in train_faces])\n",
    "        # number of faces to train\n",
    "        self.num_examples = train_faces.shape[0]\n",
    "        print ('number of training faces: %d' %self.num_examples)\n",
    "        # assuming coordinates are (x,y) pairs for each key point\n",
    "        self.num_keypoints = (int)(train_coordinates.shape[1]/2)\n",
    "        # image dimension\n",
    "        self.ncolumn = np.sqrt(train_faces.shape[1])\n",
    "        self.nrow = self.ncolumn\n",
    "        \n",
    "        # get patches and their centers for all keypoints\n",
    "        self.patches, self.patch_centers = [], []\n",
    "        for i in range(self.num_keypoints):\n",
    "            # get coordinates of current keypoint\n",
    "            coordinates = train_coordinates[:,i*2:(i+1)*2]\n",
    "            # filter zero values (empty from file)\n",
    "            picker = coordinates[:,0]>0                        \n",
    "            # get patch if at least one face has this point\n",
    "            if sum(picker)>0:\n",
    "                # get patch for this key point\n",
    "                self.patches.append(self._getPatch(train_faces[picker], coordinates[picker]))\n",
    "                # get center for this keypoint\n",
    "                self.patch_centers.append(np.mean(coordinates[picker], axis=0))\n",
    "        \n",
    "        # convert to numpy array      \n",
    "        self.patches = np.array(self.patches)\n",
    "        self.patch_centers = np.array(self.patch_centers)\n",
    "        self.num_keypoints = self.patches.shape[0]\n",
    "        self.training_time = (datetime.now()-start).total_seconds()/60.0\n",
    "        print ('training patches shape: %s' %str(self.patches.shape))\n",
    "        print ('training time: %.1f minutes' %self.training_time)\n",
    "        # show training patches\n",
    "#         self._plotPatches()\n",
    "        \n",
    "    # Make prediction for each test face and return coordinates.\n",
    "    def predict(self, test_faces):\n",
    "        start = datetime.now()\n",
    "        # stretch input if needed\n",
    "        if self.isStretch:\n",
    "            test_faces = np.array([self._histogramStretching(x) for x in test_faces])\n",
    "        self.num_predict = test_faces.shape[0]\n",
    "        print ('number of predicting faces: %d' %self.num_predict)\n",
    "        predictions = []\n",
    "        for i in range(self.num_predict):\n",
    "            if np.mod((i+1), self.num_predict/10)==0:\n",
    "                print ('Complete %d%% ...' %(100.0*(i+1)/self.num_predict))\n",
    "            pred = self._predictOneFace(test_faces[i])            \n",
    "            predictions.append(np.reshape(pred, (1,2*self.num_keypoints))[0])        \n",
    "        self.pred_coor = np.array(predictions)\n",
    "        self.predict_time = (datetime.now()-start).total_seconds()/60.0\n",
    "        print ('Done! - Predict time: %.1f minutes' %self.predict_time)\n",
    "        return self.pred_coor\n",
    "    \n",
    "    # calculate total Root Mean Squared Error (RMSE)\n",
    "    def RMSE(self, actual, pred=[]):\n",
    "        if len(pred)==0:\n",
    "            pred = self.pred_coor\n",
    "        picker = actual>0        \n",
    "        tRMSE = np.sqrt(np.sum((actual[picker]-pred[picker])**2)/np.sum(picker)) \n",
    "        return 'Total RMSE: %.2f, patch size: %d, search size: %d' %(tRMSE, self.patch_size, self.search_size)\n",
    "    \n",
    "    # save the submission file based on prediction made for test images\n",
    "    def getSubmission(self, LookupTable, feature_name):\n",
    "        # create a dictionary for feature name indexing\n",
    "        feature_index = {x:np.where(feature_name==x)[0][0] for x in feature_name}\n",
    "        lookupRow = []\n",
    "        with open(LookupTable) as csvfile:\n",
    "            # read the lookup file\n",
    "            lookupReader = csv.reader(csvfile, delimiter=',')\n",
    "            lookupRow.append(lookupReader.next())\n",
    "            for row in lookupReader:\n",
    "                # get the prediction based on image ID and feature name, and attach to the row\n",
    "                location = self.pred_coor[int(row[1])-1, feature_index[row[2]]]\n",
    "                lookupRow.append(np.append(row, location))\n",
    "        lookupRow = np.array(lookupRow)\n",
    "        # save row ID and location ID columns only to the submission file\n",
    "        saveFile = 'submission_'+datetime.now().strftime(\"%Y%m%d%H%M%S\")+'.csv'\n",
    "        with open(saveFile, 'wb') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerows(lookupRow[:,[0,3]])\n",
    "        print ('Submission file saved as: %s' %saveFile)\n",
    "        return lookupRow\n",
    "        \n",
    "    # get the prediction for one face\n",
    "    def _predictOneFace(self, face):\n",
    "        # get prediction for each keypoint available in the model\n",
    "        pred_coor = []\n",
    "        for gold_p, center in zip(self.patches, self.patch_centers):\n",
    "            # get the candidate points based on search size\n",
    "            candidates = self._getCandidates(center)\n",
    "            # get a patch for each candidate point     \n",
    "            pred_p = [self._getPatch([face], [x]) for x in candidates]\n",
    "\n",
    "            # compare the patches from candidate points with gold_p\n",
    "            # TODO: use better distance\n",
    "            dist = [np.sum(np.abs(gold_p-x)) for x in pred_p]\n",
    "            pred_coor.append(candidates[np.argmin(dist)])\n",
    "        return pred_coor\n",
    "    \n",
    "    # get the candidate points - return the coordinates\n",
    "    def _getCandidates(self, center):  \n",
    "        r, c = np.round(center)\n",
    "        candidates = np.array([[r+i, c+j] for i,j in self.search_index])\n",
    "        # only keep those within the bound\n",
    "        picker = (np.sum(candidates>=0,axis=1) + np.sum(candidates<[self.nrow,self.ncolumn],axis=1))==4        \n",
    "        return candidates[picker]\n",
    "    \n",
    "    # get the patch for one keypoint from all faces\n",
    "    def _getPatch(self, faces, keypoints):    \n",
    "        patches = []\n",
    "        for face, keypoint in zip(faces, keypoints):\n",
    "            # get keypoint pixel row and column index\n",
    "            r, c = np.round(keypoint)        \n",
    "            # get indices for the patch (including self)\n",
    "            neighbors = np.array([[r+i, c+j] for i,j in self.patch_index])\n",
    "            if np.sum(neighbors>=0)+np.sum(neighbors<[self.nrow,self.ncolumn]) == np.prod(neighbors.shape)*2:\n",
    "                patches.append(face[[r*self.ncolumn + c for r,c in neighbors]])\n",
    "#             else:\n",
    "#                 print ('warning - nonconforming patch')\n",
    "#         print (np.array(patches).shape)\n",
    "        return np.mean(patches, axis=0)\n",
    "\n",
    "    # histogram stretching pre-processing\n",
    "    def _histogramStretching(self, image):\n",
    "        # a, b = min(image), max(image) \n",
    "        a, b = np.percentile(image, 5), np.percentile(image, 95)\n",
    "        l, u = 0, 255\n",
    "        const = 1.0*(b*l - a*u)/(b - a)\n",
    "        k = 1.0*(u-l)/(b-a)\n",
    "        return [k*p+const for p in image]\n",
    "    \n",
    "    # plot average patch from training\n",
    "    def _plotPatches(self):\n",
    "        n_side = 2*self.patch_size+1\n",
    "        keypoints = np.reshape([x[:-2] for x in feature_name],(self.num_keypoints,2))\n",
    "        plt.figure(figsize=(16, 8))\n",
    "        i = 1\n",
    "        for point, patch in zip(keypoints[:,0], self.patches):\n",
    "            plt.subplot(3,5,i)\n",
    "            plt.imshow(np.reshape(patch,(n_side,n_side)), cmap = cm.gray)\n",
    "            plt.title(point)\n",
    "            plt.axis('off')\n",
    "            i += 1\n",
    "        plt.show()\n",
    "        \n",
    "\n",
    "##### Get baseline score #####\n",
    "# training\n",
    "mps = MeanPatchSearching(patch_size=9, search_size=5, stretch=True)\n",
    "mps.fit(train_faces[:150], train_coordinates[:150])\n",
    "# predicting\n",
    "predictions = mps.predict(test_faces)\n",
    "mps.getSubmission('./Data/FKD_IdLookupTable.csv', feature_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_faces' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-1f3d68d21582>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mmps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMeanPatchSearching\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstretch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_faces\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_coordinates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m# predicting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_faces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'train_faces' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'MeanPatchSearching' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-1f3d68d21582>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mMeanPatchSearching\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m9\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msearch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstretch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_faces\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_coordinates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m150\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# predicting\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpredictions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_faces\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'MeanPatchSearching' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
